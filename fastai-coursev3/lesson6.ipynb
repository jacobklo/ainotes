{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "We need to make all the features as clear for the neural network to pick up as possible.\n",
    "\n",
    "E.g. If we only have 1 feature of date, it is hard for neural network to pick up, is a pattern happen on weekend.\n",
    "\n",
    "So, we can pre-process and create a new feature called is_weekend.\n",
    "\n",
    "![](lesson6/lesson6-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastai preprocessor - Categorify\n",
    "![](lesson6/lesson6-2.png)\n",
    "\n",
    "Some of the values in the panda dataframe is a string of multiple values, this preprocessor is going to internally convert those into numbers.\n",
    "\n",
    "E.g. \"Jan,Apr,Jul,Oct\" was a string, and it is converted to list of numbers that store internally.\n",
    "\n",
    "This get all the categories shows in this column\n",
    "```\n",
    "small_train_df.PromoInterval.cat.categories\n",
    "```\n",
    "\n",
    "This show the internal number\n",
    "```\n",
    "small_train_df['PromoInterval'].cat.codes\n",
    "```\n",
    "-1 in codes means NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastai preprocessor - fill_missing\n",
    "![](lesson6/lesson6-3.png)\n",
    "Create a new boolean feature, and identify TRUE for missing data in FEATURE_na; false for otherwise\n",
    "\n",
    "For the original data that is missing, it will put median into it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastai - treat label as continuous variable explicitly\n",
    "\n",
    "We can use label_cls=FloatList, to treat label as continuous variable explicitly. On the other hand, Fastai will treat integer data as categorical variable.\n",
    "```\n",
    "data = (TabularList.from_df(df, path=path, cat_names=cat_vars, cont_names=cont_vars, procs=procs,)\n",
    "                .split_by_idx(valid_idx)\n",
    "                .label_from_df(cols=dep_var, label_cls=FloatList, log=True)\n",
    "                .add_test(TabularList.from_df(test_df, path=path, cat_names=cat_vars, cont_names=cont_vars))\n",
    "                .databunch())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Mean Square Percentage Error\n",
    "![](lesson6/lesson6-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage of Log\n",
    "\n",
    "The above example pass the label and perform log(y) immediately (log=True). We use Log when the label have long-tail distribution, like population, the amount of sales. We use when we care about the percentage differences rather than exact differences.\n",
    "\n",
    "That's why the loss function of the above example is RMSPE, instead of RMSE.\n",
    "\n",
    "It is claimed that doing a log(y) on input ( so yi now is log(yi) ), the RMSPE becomes RMSE in math, I don't know yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "![](lesson6/lesson6-5.png)\n",
    "\n",
    "Dropout will throw out some activations on each layer at random, for each batch, by given a probability. On next batch, put those back and it will be some other activation that get throw out on each layer.\n",
    "\n",
    "It means that no one activation can kind of memorize some part of the input, because that's what happen when we overfit. When we overfit, some part of the model is basically learning to recognize a particular image, rather a feature in general.\n",
    "```\n",
    "ps=[0.001,0.01]\n",
    "ps=0.01\n",
    "```\n",
    "![](lesson6/lesson6-6.png)\n",
    "At testing, we will always use all nodes ( turn off droupout ).\n",
    "\n",
    "It also say you should mutiply the weights by p, since now that all the nodes are present. The weights will not be accurate ( since some weights are dropped before ).\n",
    "\n",
    "Pytorch already did those for us, so we did not need to care about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
